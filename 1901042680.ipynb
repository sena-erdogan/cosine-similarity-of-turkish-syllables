{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0442baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mall', 'ya', 'Ya', 'nu', 'dir', 'sin', 'di', 'kon', 'na', 'to', 'ma', 'du', 'dug', 'Ta', 'red', 'sir', 'yok', 'ol', 'he', \"'i\", 'lind', 'sind', 'gil', 'gu', 'yu', 'hic', 'gol', 'b', '6', 'Agus', '122', 'gi', 'bi', 'ti', 'ka', 'ko', 'n', 'hind', 'lar', 'il', 'ru', 'den', 'Han', 'mak', 'ul', 'ri', 'ne', 'yi', 'gund', 'lun', 'ke', 'ta', 'rin', 'Gizl', 'da', 'bil', 'sap', 'bu', 'Mo', 'se', 'ih', 'Ha', '2', 'i', 'din', 'hÃ¢l', 'nus', 'gor', 'Cen', 'ce', 'tur', 'pi', 'la', 'muzd'}\n",
      "Cosine similarity between ('mall',)and('mall',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 3 2 1 0 0 0 0]\n",
      " [0 0 0 2 4 3 2 1 0 0]\n",
      " [0 0 0 1 3 5 4 3 2 1]\n",
      " [0 0 0 0 2 4 6 5 4 3]\n",
      " [0 0 1 0 1 3 5 7 6 5]\n",
      " [0 0 0 0 0 2 4 6 8 7]\n",
      " [0 0 0 0 0 1 3 5 7 9]]\n",
      "\"('mall',)\"\n",
      "\"('mall',)\"\n",
      "Cosine similarity between ('mall',)and('lind',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 1 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 1 3]]\n",
      "\"('mall',)\"\n",
      "\"('lind',)\"\n",
      "Cosine similarity between ('mall',)and('sind',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 1 3]]\n",
      "\"('mall',)\"\n",
      "\"('sind',)\"\n",
      "Cosine similarity between ('mall',)and('Agus',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 1 3]]\n",
      "\"('mall',)\"\n",
      "\"('Agus',)\"\n",
      "Cosine similarity between ('mall',)and('hind',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 1 3]]\n",
      "\"('mall',)\"\n",
      "\"('hind',)\"\n",
      "Cosine similarity between ('mall',)and('gund',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 1 3]]\n",
      "\"('mall',)\"\n",
      "\"('gund',)\"\n",
      "Cosine similarity between ('mall',)and('Gizl',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 2 1 0]\n",
      " [0 0 0 0 0 0 0 1 3 2]\n",
      " [0 0 0 0 0 0 0 0 2 4]]\n",
      "\"('mall',)\"\n",
      "\"('Gizl',)\"\n",
      "Cosine similarity between ('mall',)and('muzd',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 1 0 0]\n",
      " [0 0 1 3 2 1 0 0 0 0]\n",
      " [0 0 0 2 2 1 0 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 0 0 1 3]]\n",
      "\"('mall',)\"\n",
      "\"('muzd',)\"\n",
      "Cosine similarity between ('ya',)and('ya',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 3 2 1 0 0]\n",
      " [0 0 0 2 4 3 2 1]\n",
      " [0 0 1 1 3 5 4 3]\n",
      " [0 0 0 0 2 4 6 5]\n",
      " [0 0 0 0 1 3 5 7]]\n",
      "\"('ya',)\"\n",
      "\"('ya',)\"\n",
      "Cosine similarity between ('ya',)and('Ya',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('Ya',)\"\n",
      "Cosine similarity between ('ya',)and('nu',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('nu',)\"\n",
      "Cosine similarity between ('ya',)and('di',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('di',)\"\n",
      "Cosine similarity between ('ya',)and('na',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('na',)\"\n",
      "Cosine similarity between ('ya',)and('to',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('to',)\"\n",
      "Cosine similarity between ('ya',)and('ma',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('ma',)\"\n",
      "Cosine similarity between ('ya',)and('du',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('du',)\"\n",
      "Cosine similarity between ('ya',)and('Ta',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('Ta',)\"\n",
      "Cosine similarity between ('ya',)and('ol',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ol',)\"\n",
      "Cosine similarity between ('ya',)and('he',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('he',)\"\n",
      "Cosine similarity between ('ya',)and(\"'i\",) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 2]]\n",
      "\"('ya',)\"\n",
      "\"(\"'i\",)\"\n",
      "Cosine similarity between ('ya',)and('gu',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('gu',)\"\n",
      "Cosine similarity between ('ya',)and('yu',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 3 2 1 0 0]\n",
      " [0 0 0 2 2 1 0 0]\n",
      " [0 0 1 1 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('yu',)\"\n",
      "Cosine similarity between ('ya',)and('gi',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('gi',)\"\n",
      "Cosine similarity between ('ya',)and('bi',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('bi',)\"\n",
      "Cosine similarity between ('ya',)and('ti',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ti',)\"\n",
      "Cosine similarity between ('ya',)and('ka',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('ka',)\"\n",
      "Cosine similarity between ('ya',)and('ko',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ko',)\"\n",
      "Cosine similarity between ('ya',)and('il',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('il',)\"\n",
      "Cosine similarity between ('ya',)and('ru',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ru',)\"\n",
      "Cosine similarity between ('ya',)and('ul',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ul',)\"\n",
      "Cosine similarity between ('ya',)and('ri',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ri',)\"\n",
      "Cosine similarity between ('ya',)and('ne',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ne',)\"\n",
      "Cosine similarity between ('ya',)and('yi',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 3 2 1 0 0]\n",
      " [0 0 0 2 2 1 0 0]\n",
      " [0 0 1 1 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('yi',)\"\n",
      "Cosine similarity between ('ya',)and('ke',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('ke',)\"\n",
      "Cosine similarity between ('ya',)and('ta',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('ta',)\"\n",
      "Cosine similarity between ('ya',)and('da',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 2 1 0 0]\n",
      " [0 0 1 0 1 3 2 1]\n",
      " [0 0 0 0 0 2 4 3]\n",
      " [0 0 0 0 0 1 3 5]]\n",
      "\"('ya',)\"\n",
      "\"('da',)\"\n",
      "Cosine similarity between ('ya',)and('bu',) - CBOW :  [[-1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('bu',)\"\n",
      "Cosine similarity between ('ya',)and('Mo',) - CBOW :  [[1.]]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 1 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 2 1]\n",
      " [0 0 0 0 0 0 1 3]]\n",
      "\"('ya',)\"\n",
      "\"('Mo',)\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 173\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine similarity between \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(g1) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(g2) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - CBOW : \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(model2\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39msimilarity(g1, g2)))\n\u001b[1;32m    171\u001b[0m                 check(\u001b[38;5;28mstr\u001b[39m(g1), \u001b[38;5;28mstr\u001b[39m(g2))\n\u001b[0;32m--> 173\u001b[0m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki_00.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [55], line 165\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine similarity between \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(g1) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(g2) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - CBOW : \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(model1\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39msimilarity(g1, g2)))\n\u001b[1;32m    163\u001b[0m             check(\u001b[38;5;28mstr\u001b[39m(g1), \u001b[38;5;28mstr\u001b[39m(g2))\n\u001b[0;32m--> 165\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_grams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g1 \u001b[38;5;129;01min\u001b[39;00m ngrams(syl_set, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m g2 \u001b[38;5;129;01min\u001b[39;00m ngrams(syl_set, \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_total_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/word2vec.py:1045\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha \u001b[38;5;241m=\u001b[39m end_alpha \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[0;32m-> 1045\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_training_sanity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1050\u001b[0m     msg\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     ),\n\u001b[1;32m   1055\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/models/word2vec.py:1543\u001b[0m, in \u001b[0;36mWord2Vec._check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1540\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEffective \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m higher than previous training cycles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mkey_to_index:  \u001b[38;5;66;03m# should be set by `build_vocab`\u001b[39;00m\n\u001b[0;32m-> 1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must first build vocabulary before training the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors):\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must initialize vectors before training the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "import ngram\n",
    "import re\n",
    "import gensim\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import ngrams\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def backtrace(matrix, line1, line2):\n",
    "    i = len(line1)\n",
    "    j = len(line2)\n",
    "    \n",
    "    while i > 0 and j > 0:\n",
    "        if matrix[i][j] == ((matrix[i-1][j-1])+1):\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def matrix_filling(matrix, line1, line2, match, mismatch):\n",
    "    for i in range(1, len(line1)+1):\n",
    "        for j in range(1, len(line2)+1):\n",
    "            if line1[j-1] == line2[i-1]:\n",
    "                a = matrix[i-1][j-1] + match\n",
    "            else:\n",
    "                a = matrix[i-1][j-1] + mismatch\n",
    "            \n",
    "            b = matrix[i][j-1] + mismatch\n",
    "            c = matrix[i-1][j] + mismatch\n",
    "            \n",
    "            m = max(max(a,b), c)\n",
    "            \n",
    "            if m < 0:\n",
    "                matrix[i][j] = 0\n",
    "            else:\n",
    "                matrix[i][j] = m\n",
    "                \n",
    "    print(matrix)\n",
    "    print('\"' + line1 + '\"')\n",
    "    print('\"' + line2 + '\"')\n",
    "\n",
    "def check(line1, line2):\n",
    "    if len(line1) == len(line2) and line1 != \"\\n\" and line2 != \"\\n\":\n",
    "        matrix = np.zeros((len(line1)+1, len(line2)+1), int)\n",
    "        matrix_filling(matrix, line1, line2, 1, -1)\n",
    "        \n",
    "def smith_waterman(text1, text2):\n",
    "    print(\"start of \", text1, text2)\n",
    "    \n",
    "    file1 = open('texts/' + text1, 'r')\n",
    "    f1 = file1.readlines()\n",
    "    file2 = open('texts/' + text2, 'r')\n",
    "    f2 = file2.readlines()\n",
    "    for line1 in f1:\n",
    "        for line2 in f2:\n",
    "            check(line1, line2)\n",
    "    print(\"end of \", text1, text2)\n",
    "\n",
    "def into_syllable(word, syl_set):\n",
    "    syllables = []\n",
    "\n",
    "    bits = ''.join(['1' if l in 'aeiou' else '0' for l in word])\n",
    "\n",
    "    seperators = (\n",
    "        ('101', 1),\n",
    "        ('1001', 2),\n",
    "        ('10001', 3)\n",
    "    )\n",
    "\n",
    "    index, cut_start_pos = 0, 0\n",
    "\n",
    "    while index < len(bits):\n",
    "\n",
    "        for seperator_pattern, seperator_cut_pos in seperators:\n",
    "            if bits[index:].startswith(seperator_pattern):\n",
    "\n",
    "                syllables.append(word[cut_start_pos:index + seperator_cut_pos])\n",
    "\n",
    "                index += seperator_cut_pos\n",
    "                cut_start_pos = index\n",
    "                break\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    syllables.append(word[cut_start_pos:])\n",
    "    return syllables\n",
    "\n",
    "def gram1(syl_set,dict_1):\n",
    "    for syl1 in syl_set:\n",
    "        for syl2 in syl_set:\n",
    "            if ngram.NGram.compare(syl1,syl2,N=1) != 0:\n",
    "                key = syl1+'*'+syl2\n",
    "                dict_1[key] = ngram.NGram.compare(syl1,syl2,N=1)\n",
    "                \n",
    "    for key in dict_1:\n",
    "        print(key + '\\t' + str(dict_1[key]))\n",
    "            \n",
    "def gram2(syl_set,dict_2):\n",
    "    for syl1 in syl_set:\n",
    "        for syl2 in syl_set:\n",
    "            for syl3 in syl_set:\n",
    "                if ngram.NGram.compare(syl1,syl2,syl3,N=2) != 0:\n",
    "                    key = syl1+'*'+syl2+'*'+syl3\n",
    "                    dict_2[key] = ngram.NGram.compare(syl1,syl2,syl3,N=2)\n",
    "                \n",
    "    for key in dict_2:\n",
    "        print(key + '\\t' + str(dict_2[key]))\n",
    "        \n",
    "def gram3(syl_set,dict_3):\n",
    "    for syl1 in syl_set:\n",
    "        for syl2 in syl_set:\n",
    "            for syl3 in syl_set:\n",
    "                for syl4 in syl_set:\n",
    "                    if ngram.NGram.compare(syl1,syl2,syl3,syl4,N=3) != 0:\n",
    "                        key = syl1+'*'+syl2+'*'+syl3+'*'+syl4\n",
    "                        dict_3[key] = ngram.NGram.compare(syl1,syl2,syl3,syl4,N=3)\n",
    "                \n",
    "    for key in dict_3:\n",
    "        print(key + '\\t' + str(dict_3[key]))\n",
    "\n",
    "def read_file(text):\n",
    "    syl_set = set([])\n",
    "    file = open(text, 'r')\n",
    "    f = file.readlines()\n",
    "    for line in f:\n",
    "        for word in re.split('. | ', line):\n",
    "            for syl in into_syllable(word, syl_set):\n",
    "                syl_set.add(syl)\n",
    "                \n",
    "    print(syl_set)\n",
    "    \n",
    "    dict_1 = {}\n",
    "    dict_2 = {}\n",
    "    dict_3 = {}\n",
    "    \n",
    "    #gram1(syl_set,dict_1)\n",
    "    #gram2(syl_set,dict_2)\n",
    "    #gram3(syl_set,dict_3)\n",
    "    \n",
    "    n_grams = ngrams(syl_set, 1)\n",
    "   # for grams in n_grams:\n",
    "   #     print(grams)\n",
    "        \n",
    "   # n_grams = ngrams(syl_set, 2)\n",
    "   # for grams in n_grams:\n",
    "     #   print(grams)\n",
    "        \n",
    "   # n_grams = ngrams(syl_set, 3)\n",
    "   # for grams in n_grams:\n",
    "   #     print(grams)\n",
    "        \n",
    "    model1 = gensim.models.Word2Vec(n_grams, min_count = 1, vector_size = 1, window = 5)\n",
    "\n",
    "    for g1 in ngrams(syl_set, 1):\n",
    "        for g2 in ngrams(syl_set, 1):\n",
    "            if len(str(g1)) == len(str(g2)):\n",
    "                print(\"Cosine similarity between \" + str(g1) + \"and\" + str(g2) + \" - CBOW : \", str(model1.wv.similarity(g1, g2)))\n",
    "                check(str(g1), str(g2))\n",
    "\n",
    "    model2 = gensim.models.Word2Vec(n_grams, min_count = 1, vector_size = 1,window = 5, sg = 1)\n",
    " \n",
    "    for g1 in ngrams(syl_set, 1):\n",
    "        for g2 in ngrams(syl_set, 1):\n",
    "            if len(str(g1)) == len(str(g2)):\n",
    "                print(\"Cosine similarity between \" + str(g1) + \"and\" + str(g2) + \" - CBOW : \", str(model2.wv.similarity(g1, g2)))\n",
    "                check(str(g1), str(g2))\n",
    "            \n",
    "read_file(\"wiki_00.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec2c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
